beads_volume_muL <- 10 # added in Transfer 2
# ----
# -- flow cytometer settings --
set_flow_rate_muL_s <- 0.5
# ----
# --
# - inputs for saving the data -
savepath <- "/Users/jvb740/MarieCurie_Work/CellCounting_TaskForce/FlowCytometryAnalysis/Results"
savename <- NULL
# --
source(file.path(functionpath, function_file))
files <- list.files(datapath)
files <- files[grepl("*.fcs", files)]
fcsFileList <- lapply(file.path(datapath, files), read.FCS, transformation=FALSE)
# fcsFileList <- lapply(file.path(datapath, files), read.FCS, transformation=FALSE, column.pattern = "-W|-H", invert.pattern = TRUE)
names(fcsFileList) <- files
ParameterValuesList <- lapply(fcsFileList, extract_parameter_keywords_from_flowFrame)
# -- test that at least all but BS and MS are identical --
ParameterValuesList_Restricted <- lapply(ParameterValuesList, function(DF){
DF <- DF[c("N", "R", "B", "E", "V", "G", "DISPLAY")]
rownames(DF) <- NULL
DF
})
if (length(unique(ParameterValuesList_Restricted)) == 1) {
PrintList <- ParameterValuesList[[1]]
} else {
PrintList <- ParameterValuesList
}
# --
PrintList
nonParameterValuesList <- lapply(fcsFileList, extract_all_non_parameter_keywords_from_flowFrame)
# - reorder based on the wells -
WellIDs <- vapply(nonParameterValuesList, function(DF){DF$Value[DF$Keyword == "WELL ID"]}, character(1))
fcsFileList <- fcsFileList[order(WellIDs)]
# --
# -- check that the length are equal (better would be to check that all Keywords are identical) --
if(length(unique(vapply(nonParameterValuesList, nrow, numeric(1)))) == 1) {
nPV_DF <- do.call("cbind", nonParameterValuesList)
nPV_DF <- nPV_DF[, c(1, seq(2, ncol(nPV_DF), by = 2))]
# -- reorder based on WellIDs --
nPV_DF <- dplyr::select(nPV_DF, Keword = 1, (order(WellIDs)+1))
# ----
} else {
nPV_DF <- NULL
}
knitr::kable(nPV_DF, caption = "Table of non-parameter related keywords")
nPV_DF
nonParameterValuesList <- lapply(fcsFileList, extract_all_non_parameter_keywords_from_flowFrame)
# - reorder based on the wells -
WellIDs <- vapply(nonParameterValuesList, function(DF){DF$Value[DF$Keyword == "WELL ID"]}, character(1))
fcsFileList <- fcsFileList[order(WellIDs)]
vapply(nonParameterValuesList, nrow, numeric(1))
fs <- as(fcsFileList, "flowSet")
KeywordTable <- as.data.frame(keyword(fs, c("$TOT", "$PAR", "TUBE NAME", "THRESHOLD", "$DATE", "EXPORT TIME", "$BTIM", "$ETIM")), stringsAsFactors = FALSE)
KeywordTable <- cbind(data.frame(Index = 1:nrow(KeywordTable), Sample = rownames(KeywordTable)), KeywordTable, stringsAsFactors = FALSE)
rownames(KeywordTable) <- NULL
KeywordTable$`$TOT` <- as.numeric(as.character(KeywordTable$`$TOT`))
# change sample Names
# flowWorkspace::sampleNames(fs) <- paste(Prefix, fs@phenoData@data$well, fs@phenoData@data$SRC, sep = "_")
#
# rownames(KeywordTable) <- flowWorkspace::sampleNames(fs)
KeywordTable$`$BTIM` <- hms(KeywordTable$`$BTIM`)
KeywordTable$`$ETIM` <- hms(KeywordTable$`$ETIM`)
KeywordTable$RecTime_sec <- as.numeric(as.duration(KeywordTable$`$ETIM`- KeywordTable$`$BTIM`), "seconds")
# - new add the run time from the exprs data -
Maximums <- as.data.frame(fsApply(fs, each_col, max))
Minimums <- as.data.frame(fsApply(fs, each_col, min))
KeywordTable$RunTime_sec <- (Maximums$Time - Minimums$Time)/100
KeywordTable$Events_per_sec <- KeywordTable$`$TOT`/KeywordTable$RunTime_sec
# --
knitr::kable(KeywordTable, caption = "summary of key keywords with running times added.")
# Determine Minimum values of the different parameters in the different samples
MatrixList <- lapply(1:length(fs), FUN = function(x){exprs(fs[[x]])})
names(MatrixList) <- flowWorkspace::sampleNames(fs)
MinimumsAbove0 <- t(sapply(MatrixList, function(x){apply(x, 2, function(y) min(y[y>0]))}))
# MinimumsAbove0 <- fsApply(fs, each_col, function(x){min(x[x>0])})
BigDF <- as.data.frame(do.call("rbind", MatrixList))
Discretized <- lapply(BigDF, function(x){head(sort(unique(x[x>0])), 10)})
Discretized <- do.call("cbind", Discretized)
rm(BigDF)
# Determine Minimum values of the different parameters in the different samples
knitr::kable(Minimums, caption = "Minimums")
knitr::kable(MinimumsAbove0, caption = "Minimums above 0")
knitr::kable(Maximums, caption = "Maximums")
knitr::kable(Discretized, caption = "Discretized steps above 0")
gs <- GatingSet(fs) # also GatingSets are S4 objects
Gate.Area <- rectangleGate(filterId = "Area", list("FSC-A" = c(FSC.A.low, FSC.A.high), "SSC-A" = c(SSC.A.low, SSC.A.high)))
# add the gate to the gs
add(gs, Gate.Area, parent = "root")
# gate the data
recompute(gs)
gatingStats <- gs.Stats(gs)
View(KeywordTable)
View(PrintList)
TrL <- FC.geom_hex(fs = getData(gs, "/Area"), x = "Pacific Blue-A", y = "APC-Cy7-A", bins = bins, co.fix = TRUE, xlimits = c(0.1, 300000), ylimits = c(.1,300000), trans = "log10", colPalette = NULL, ncolors = 10)
TrL[[1]]
TrL[[2]]
TrL[[3]]
TrL[[4]]
TrL[[5]]
TrL[[6]]
TrL[[7]]
TrL[[1]]
TrL[[8]]
TrL[[9]]
TrL[[3]]
rm(list = ls())
rm(list = ls())
shiny::runApp('Coursera_MOOC/20161202_LearningShiny_FantasySports/shinyy/Apps/Shinyappsio/Ibenerary2')
rm(list = ls())
library(phyloseq); # packageVersion("phyloseq")
library(ggplot2); # packageVersion("ggplot2")
library(dplyr); # packageVersion("dplyr")
library(tidyr); # packageVersion("tidyr")
library(gridExtra);
# source("https://bioconductor.org/biocLite.R")
# biocLite("Biostrings")
library(Biostrings)
library(xtable)
datapath <- "/Users/jvb740/MarieCurie_Work/Project_FungomeQuantification/Sequences_FungomeQuantification"
name_current_database <- "silva_species_assignment_v132.fa" # In case you are looking for a genus or even species this is probably
#name_current_database <- "silva_nr_v132_train_set.fa"
DB <- readDNAStringSet(filepath = file.path(datapath, name_current_database), format = "fasta")
length(DB) # 313502 sequences
# --
# - explore and prepare the data base, i.e. restrict it to sequences that pass some filters -
# -- only keep unique seuqences --
# even if the assignments would differ, we would probably not care
length(unique(as.character(DB))) #186251 so several sequences are several times in
DB_unique <- unique(DB)
DB <- DB_unique
rm(DB_unique)
# ----
# -- understand and record the taxonomy of the sequences --
typeof(DB) # S4 object
names(attributes(DB))
head(DB@ranges)
# the taxonomy information is in the names
names(DB)[1:2] # in this case taxonomic information is separated by ;
nameList <- strsplit(names(DB), split = " ")
# looking at it, makes me think that first entry is an identifier, then Genus, then Species
# we will miss some parts of species names by only going to 3 here, but should do it for our purpose, especially genus should be fine
Taxonomies <- list()
for (i in 1:3){
Taxonomies[[i]] <- vapply(nameList, "[", FUN.VALUE = character(1), i)
}
names(Taxonomies) <- c("ID", "Genus", "Species")
# look at the Genera:
table(Taxonomies[["Genus"]])
# generate a data frame that gives you an overview of the DB
DB_DF <- cbind(Index = 1:length(DB), as.data.frame(vapply(Taxonomies, identity, character(length(DB))), stringsAsFactors = FALSE))
DB_DF$Length <- width(DB)
# one could add the sequences
DB_DF$Sequence <- DB
DB_DF$Sequence <- as.character(DB_DF$Sequence)
# length(unique(DB_DF$Sequence))
# ----
# -- restrict to sequences in a certain size range --
table(DB_DF$Length)
# both test sequences I will use (Bacteroides and E.coli) are around 1500 bp long, so I think it is fair to restrict to sequences bw 1400 > 1750
DB_DF <- dplyr::filter(DB_DF, Length >= 1350, Length <= 1750)
# ----
# -- you could restrict to sequences without IUPAC-CODE-characters other than AGCT --
# NB: this grepl goes through all sequeences and thus takes a while
DB_DF <- dplyr::filter(DB_DF, !grepl(paste(names(IUPAC_CODE_MAP)[-(1:4)], collapse = "|"), Sequence))
# ----
# -- go to the final Data Base --
DB_final <- DB[DB_DF$Index]
# ----
totalNoOfSequences <- length(DB_final)
# This procedure left you with a DataBase of 144348
# --
TOI <- "difficile"
rank <- "Species"
DB_DF_TOI <- DB_DF[DB_DF[[rank]] == TOI, ]
View(DB_DF_TOI)
table(DB_DF_TOI$Genus)
totalNoOfSequences_TOI <- length(DB_TOI)
DB_TOI <- DB[DB_DF_TOI$Index]
totalNoOfSequences_TOI <- length(DB_TOI)
Primer515F_A <- "GTGCCAGCAGCCGCGGTAA"
Primer515F_C <- "GTGCCAGCCGCCGCGGTAA"
# Primer806R <- DNAString("GGACTACHVGGGTWTCTAAT")
Primer806R_C_A_A <- "GGACTACCAGGGTATCTAAT"
Primer806R_A_A_A <- "GGACTACAAGGGTATCTAAT"
Primer806R_T_A_A <- "GGACTACTAGGGTATCTAAT"
Primer806R_C_C_A <- "GGACTACCCGGGTATCTAAT"
Primer806R_A_C_A <- "GGACTACACGGGTATCTAAT"
Primer806R_T_C_A <- "GGACTACTCGGGTATCTAAT"
Primer806R_C_G_A <- "GGACTACCGGGGTATCTAAT"
Primer806R_A_G_A <- "GGACTACAGGGGTATCTAAT"
Primer806R_T_G_A <- "GGACTACTGGGGTATCTAAT"
Primer806R_C_A_T <- "GGACTACCAGGGTTTCTAAT"
Primer806R_A_A_T <- "GGACTACAAGGGTTTCTAAT"
Primer806R_T_A_T <- "GGACTACTAGGGTTTCTAAT"
Primer806R_C_C_T <- "GGACTACCCGGGTTTCTAAT"
Primer806R_A_C_T <- "GGACTACACGGGTTTCTAAT"
Primer806R_T_C_T <- "GGACTACTCGGGTTTCTAAT"
Primer806R_C_G_T <- "GGACTACCGGGGTTTCTAAT"
Primer806R_A_G_T <- "GGACTACAGGGGTTTCTAAT"
Primer806R_T_G_T <- "GGACTACTGGGGTTTCTAAT"
ForwardPrimer <- c(Primer515F_A = Primer515F_A, Primer515F_C = Primer515F_C)
ReversePrimer <- c(Primer806R_C_A_A = Primer806R_C_A_A, Primer806R_A_A_A = Primer806R_A_A_A, Primer806R_T_A_A = Primer806R_T_A_A,
Primer806R_C_C_A = Primer806R_C_C_A, Primer806R_A_C_A = Primer806R_A_C_A, Primer806R_T_C_A = Primer806R_T_C_A,
Primer806R_C_G_A = Primer806R_C_G_A, Primer806R_A_G_A = Primer806R_A_G_A, Primer806R_T_G_A = Primer806R_T_G_A,
Primer806R_C_A_T = Primer806R_C_A_T, Primer806R_A_A_T = Primer806R_A_A_T, Primer806R_T_A_T = Primer806R_T_A_T,
Primer806R_C_C_T = Primer806R_C_C_T, Primer806R_A_C_T = Primer806R_A_C_T, Primer806R_T_C_T = Primer806R_T_C_T,
Primer806R_C_G_T = Primer806R_C_G_T, Primer806R_A_G_T = Primer806R_A_G_T, Primer806R_T_G_T = Primer806R_T_G_T)
ReversePrimer
DB_TOI
Fprimer <- ForwardPrimer
Rprimer <- ReversePrimer
DNA_string_set <- DB_TOI
PrimerCombis <- expand.grid(Fprimer, Rprimer)
PrimerNames <- expand.grid(names(Fprimer), names(Rprimer))
PrimerNames[] <- lapply(PrimerNames, as.character)
PrimerNames
PrimerCombis
DNA_string_set_amplicon <- DNA_string_set
Fprimers = vector(mode = "character", length = length(DNA_string_set_amplicon))
Rprimers = vector(mode = "character", length = length(DNA_string_set_amplicon))
FprimerNames = vector(mode = "character", length = length(DNA_string_set_amplicon))
RprimerNames = vector(mode = "character", length = length(DNA_string_set_amplicon))
i = 1
InputSeq <- DNAString(paste(DNA_string_set_amplicon[i]))
InputSeq
# -- define a function to extract the amplicons --
# NB: always only extracts the first amplicon, so if two primer combinations would result in an amplicon only the first is recorded
collect_V4_amplicons <- function(DNA_string_set, Fprimer, Rprimer) {
PrimerCombis <- expand.grid(Fprimer, Rprimer)
PrimerNames <- expand.grid(names(Fprimer), names(Rprimer))
PrimerNames[] <- lapply(PrimerNames, as.character)
DNA_string_set_amplicon <- DNA_string_set
Fprimers = vector(mode = "character", length = length(DNA_string_set_amplicon))
Rprimers = vector(mode = "character", length = length(DNA_string_set_amplicon))
FprimerNames = vector(mode = "character", length = length(DNA_string_set_amplicon))
RprimerNames = vector(mode = "character", length = length(DNA_string_set_amplicon))
for (i in 1:length(DNA_string_set_amplicon)) {
InputSeq <- DNAString(paste(DNA_string_set_amplicon[i]))
for (j in 1:nrow(PrimerCombis)){
Fprimer <- DNAString(PrimerCombis[j,1])
Rprimer <- DNAString(PrimerCombis[j,2])
Amplicon <- matchProbePair(Fprobe = Fprimer, Rprobe = Rprimer, InputSeq)
if (length(Amplicon) > 0 ) {
DNA_string_set_amplicon[[i]] <- Amplicon[[1]]
Fprimers[i] <- as.character(Fprimer)
Rprimers[i] <- as.character(Rprimer)
FprimerNames[i] <- PrimerNames[j, 1]
RprimerNames[i] <- PrimerNames[j, 2]
break
}
}
}
UsedPrimer <- data.frame(Fprimer = Fprimers, Rprimer = Rprimers, FprimerName = FprimerNames, RprimerName = RprimerNames)
list(DNA_string_set_amplicon, UsedPrimer)
}
# -- define a function to extract the amplicons --
# NB: always only extracts the first amplicon, so if two primer combinations would result in an amplicon only the first is recorded
collect_amplicons <- function(DNA_string_set, Fprimer, Rprimer) {
PrimerCombis <- expand.grid(Fprimer, Rprimer)
PrimerNames <- expand.grid(names(Fprimer), names(Rprimer))
PrimerNames[] <- lapply(PrimerNames, as.character)
DNA_string_set_amplicon <- DNA_string_set
Fprimers = vector(mode = "character", length = length(DNA_string_set_amplicon))
Rprimers = vector(mode = "character", length = length(DNA_string_set_amplicon))
FprimerNames = vector(mode = "character", length = length(DNA_string_set_amplicon))
RprimerNames = vector(mode = "character", length = length(DNA_string_set_amplicon))
for (i in 1:length(DNA_string_set_amplicon)) {
InputSeq <- DNAString(paste(DNA_string_set_amplicon[i]))
for (j in 1:nrow(PrimerCombis)){
Fprimer <- DNAString(PrimerCombis[j,1])
Rprimer <- DNAString(PrimerCombis[j,2])
Amplicon <- matchProbePair(Fprobe = Fprimer, Rprobe = Rprimer, InputSeq)
if (length(Amplicon) > 0 ) {
DNA_string_set_amplicon[[i]] <- Amplicon[[1]]
Fprimers[i] <- as.character(Fprimer)
Rprimers[i] <- as.character(Rprimer)
FprimerNames[i] <- PrimerNames[j, 1]
RprimerNames[i] <- PrimerNames[j, 2]
break
}
}
}
UsedPrimer <- data.frame(Fprimer = Fprimers, Rprimer = Rprimers, FprimerName = FprimerNames, RprimerName = RprimerNames)
list(DNA_string_set_amplicon, UsedPrimer)
}
resList <- collect_amplicons(DNA_string_set = DB_TOI, Fprimer = ForwardPrimer, Rprimer = ReversePrimer)
names(resList)
length(resList)
Amplicons <- resList[[1]]
usedPrimer <- resList[[2]]
Amplicons
usedPrimer
width(Amplicons)
table(width(Amplicons))
# -- restrict to amplicons < 300 bp --
keepIndexes <- width(Amplicons) < 300
keepIndexes
Amplicons <- Amplicons[keepIndexes]
length(Amplicons)
dim(usedPrimer)
usedPrimer <- usedPrimer[keepIndexes,]
Amplicons
names(Amplicons)
length(unique(Amplicons))
table(width(Amplicons))
# -- in fact vast majority of amplicons is 291 bp long --
keepIndexes <- width(Amplicons) == 291
Amplicons291 <- Amplicons[keepIndexes]
usedPrimer291 <- usedPrimer[keepIndexes,]
length(unique(Amplicons291))
colnames(usedPrimer291)
table(usedPrimer291$Fprimer)
View(usedPrimer291)
unique(usedPrimer)
# usedPrimer291 <- usedPrimer[keepIndexes,]
Amplicons291unique <- unique(Amplicons291)
Ampliocns291unique
Amplicons291unique
names(Amplicons291unique)
getwd()
savepath <- "/Users/jvb740/MarieCurie_Work/Project_FungomeQuantification/PrimerFindingCode_FungomeQuantification"
writeXStringSet(Amplicons291unique, filepath = file.path(savepath, "Clostridioides_difficile_291bpV4.fa"))
table(Amplicons)
unique(usedPrimer)
rm(list = ls())
library(phyloseq); # packageVersion("phyloseq")
library(ggplot2); # packageVersion("ggplot2")
library(dplyr); # packageVersion("dplyr")
library(tidyr); # packageVersion("tidyr")
library(gridExtra);
# source("https://bioconductor.org/biocLite.R")
# biocLite("Biostrings")
library(Biostrings)
library(xtable)
# - 1.) read in the fasta file silva database with fungal 16S sequences using Biostrings -
datapath <- "/Users/jvb740/MarieCurie_Work/Project_FungomeQuantification/Sequences_FungomeQuantification"
name_current_database <- "silva_species_assignment_v132.fa" # In case you are looking for a genus or even species this is probably
#name_current_database <- "silva_nr_v132_train_set.fa"
DB <- readDNAStringSet(filepath = file.path(datapath, name_current_database), format = "fasta")
length(DB) # 313502 sequences
length(unique(as.character(DB))) #186251 so several sequences are several times in
DB_unique <- unique(DB)
DB <- DB_unique
rm(DB_unique)
# ----
# -- understand and record the taxonomy of the sequences --
typeof(DB) # S4 object
names(attributes(DB))
head(DB@ranges)
# the taxonomy information is in the names
names(DB)[1:2] # in this case taxonomic information is separated by ;
nameList <- strsplit(names(DB), split = " ")
# looking at it, makes me think that first entry is an identifier, then Genus, then Species
# we will miss some parts of species names by only going to 3 here, but should do it for our purpose, especially genus should be fine
Taxonomies <- list()
for (i in 1:3){
Taxonomies[[i]] <- vapply(nameList, "[", FUN.VALUE = character(1), i)
}
names(Taxonomies) <- c("ID", "Genus", "Species")
# look at the Genera:
table(Taxonomies[["Genus"]])
# generate a data frame that gives you an overview of the DB
DB_DF <- cbind(Index = 1:length(DB), as.data.frame(vapply(Taxonomies, identity, character(length(DB))), stringsAsFactors = FALSE))
DB_DF$Length <- width(DB)
# one could add the sequences
DB_DF$Sequence <- DB
DB_DF$Sequence <- as.character(DB_DF$Sequence)
# length(unique(DB_DF$Sequence))
# ----
# -- restrict to sequences in a certain size range --
table(DB_DF$Length)
# both test sequences I will use (Bacteroides and E.coli) are around 1500 bp long, so I think it is fair to restrict to sequences bw 1400 > 1750
DB_DF <- dplyr::filter(DB_DF, Length >= 1350, Length <= 1750)
# ----
# -- you could restrict to sequences without IUPAC-CODE-characters other than AGCT --
# NB: this grepl goes through all sequeences and thus takes a while
DB_DF <- dplyr::filter(DB_DF, !grepl(paste(names(IUPAC_CODE_MAP)[-(1:4)], collapse = "|"), Sequence))
# ----
# -- go to the final Data Base --
DB_final <- DB[DB_DF$Index]
# ----
totalNoOfSequences <- length(DB_final)
# This procedure left you with a DataBase of 144348
# --
# - 1b.) make a DB with only the taxa of interest -
# TOI <- "Clostridioides"
# rank <- "Genus"
TOI <- "difficile"
rank <- "Species"
DB_DF_TOI <- DB_DF[DB_DF[[rank]] == TOI, ]
View(DB_DF_TOI)
DB_TOI <- DB[DB_DF_TOI$Index]
totalNoOfSequences_TOI <- length(DB_TOI)
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/F18FTSEUHT1240-01_BACllxM/Dada_Analysis_NoTrimming/Dada_Data/"
list.files(datapath)
load(file.path(datapath, "DenoisedData.RData"))
colnames(seqtab.nochim)
table(nchar(colnames(seqtab.nochim)))
rm(list = ls())
datapath <- "/Users/jvb740/MarieCurie_Work/Project_Normalization/F18FTSEUHT1240-01_BACllxM/Dada_Analysis_NoTrimming/Dada_Data/"
load(file.path(datapath, "DenoisedData.RData"))
functpath <- "/Users/jvb740/MarieCurie_Work/BackgroundKnowledge/16S_Learning/Dada_Pipel/Functions"
source(file.path(functpath, "Dada_TaxonomyFunctions.R"))
rm(list = ls())
rm(list = ls())
time_it <- function(f) {
force(f)
function(...) {
system.time(f(...))
}
}
library(pryr)
f <- function(a) g(a, b = 1)
compact <- function(x) Filter(Negate(is.null), x)
?partial
pryr::partial
compact1 <- function(x) Filter(Negate(is.null), x)
compact2 <- partial(Filter, Negate(is.null))
compact1
compact2
# understand the lazy evaluation
f <- partial(runif, n = rpois(1, 5))
f
f()
f()
rpois(1,5)
rpois(1,5)
f <- partial(runif, n = rpois(1, 5), .lazy = FALSE)
f
my_long_variable <- 1:10
plot2 <- partial(plot, my_long_variable)
plot2()
plot2(runif(10), type = "l")
plot2
plot3 <- partial(plot, my_long_variable, .lazy = T)
plot3
plot3 <- partial(plot, my_long_variable, .lazy = F)
plot3
plot3(runif(10), type = "l")
# instead of
funs2 <- list(
sum = function(...) sum(..., na.rm = TRUE),
mean = function(...) mean(..., na.rm = TRUE),
median = function(...) median(..., na.rm = TRUE)
)
funs2
# we can write
funs2 <- list(
sum = partial(sum, na.rm = TRUE),
mean = partial(mean, na.rm = TRUE),
median = partial(median, na.rm = TRUE)
)
funs2[[1]](1:10)
funs2[[2]](1:10)
funs2[[3]](1:10)
median(1:10)
# remember Map()
xs <- replicate(5, runif(10), simplify = FALSE)
xs
ws <- replicate(5, rpois(10, 5) + 1, simplify = FALSE)
ws
Map(weighted.mean, xs, ws)
ws[[2]][2]
ws[[2]][2] <- NA
Map(weighted.mean, xs, ws)
# so you can always convert a Map to an lapply that iterates over indices, but Map is more concise.
# but if some arguments need to be fixed you need an anonymous function
Map(function(x, w) weighted.mean(x, w, na.rm = TRUE), xs, ws)
xs
ws
weighted.mean(xs[[2]], ws[[2]])
weighted.mean(xs[[2]], ws[[2]], na.rm = T)
ws[[2]][2] <- 7
xs[[2]][2] <- NA
Map(weighted.mean, xs, ws)
# so you can always convert a Map to an lapply that iterates over indices, but Map is more concise.
# but if some arguments need to be fixed you need an anonymous function
Map(function(x, w) weighted.mean(x, w, na.rm = TRUE), xs, ws)
# now with partial() it will look like that
Map(partial(weighted.mean, na.rm = TRUE), xs, ws)
rm(list = ls())
2.5e11/5e10
1e10/5e9
setwd("~/MarieCurie_Work/CellCounting_TaskForce/FlowCytometryAnalysis/DIRECT")
LookUp <- data.frame(Tube = c(paste0("A", 1:12),
paste0("B", 1:12),
paste0("C", 1:12),
paste0("D", 1:12),
paste0("E", 1:12),
paste0("F", 1:12),
paste0("G", 1:12),
paste0("H", 1:12)),
Person = c("Control", 1, "Control", 25:30, 25:27,
1:12,
1:12,
1:12,
13:24,
13:24,
13:24,
28:30, 25:30, "Control", "Control", "Buffer"),
Replicate = c(NA, NA, rep("r1", 7), rep("r2", 3),
rep("r1", 12),
rep("r2", 12),
rep("r3", 12),
rep("r1", 12),
rep("r2", 12),
rep("r3", 12),
rep("r2", 3), rep("r3", 6), "r2", "r3", NA),
Stain = c(rep("unstained", 2), rep("stained", 94)))
View(LookUp)
rm(list = ls())
